{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ecbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63935535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b29e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb86e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a75977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which column is the output we want to predict?\n",
    "#The type column\n",
    "\n",
    "#Are all columns numeric?\n",
    "#yes\n",
    "\n",
    "#Is there an ID column that should not be used?\n",
    "#Yes, the Id column is only an identifier and should not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ba9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  y\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0  1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0  1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0  1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0  1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"]=(df[\"Type\"]==1).astype(int)\n",
    "df = df.drop(\"Type\",axis=1)\n",
    "df.head()\n",
    "\n",
    "#What This Step Does\n",
    "#Creates a binary output column y.\n",
    "\n",
    "#Why It Is Needed\n",
    "#Logistic regression is a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5f433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"y\",axis=1)\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c5683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#What This Step Does\n",
    "#Split the data into training and testing sets.\n",
    "\n",
    "#Why It Is Needed\n",
    "#We must test on unseen data.\n",
    "#Testing on training data gives false confidence.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d20726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()   \n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "#What This Step Does\n",
    "#Scales the features to have mean 0 and standard deviation 1.\n",
    "\n",
    "#Why It Is Needed\n",
    "#Logistic regression can be sensitive to feature scales.\n",
    "#Scaling can improve convergence and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c181abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "#What This Step Does\n",
    "#Defines the sigmoid function.  \n",
    "\n",
    "#Why It Is Needed\n",
    "#Logistic regression uses the sigmoid function to convert linear outputs into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8eb0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(X, w, b):\n",
    "    z = X @ w + b\n",
    "    p = sigmoid(z)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c90338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,p):\n",
    "    loss = -y*np.log(p) - (1-y)*np.log(1-p)\n",
    "    return np.mean(loss)\n",
    "\n",
    "#What This Step Does\n",
    "#Defines the logistic loss function.\n",
    "\n",
    "#Why It Is Needed\n",
    "#The loss function measures how well the model's predictions match the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94296540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(X, y, w, b, lr):\n",
    "    p = predict_probability(X, w, b)\n",
    "    error = p - y\n",
    "    w -= lr * (X.T @ error) / len(y)\n",
    "    b -= lr * np.mean(error)\n",
    "    return w, b\n",
    "\n",
    "#What This Step Does\n",
    "#Performs one step of gradient descent to update the weights and bias.\n",
    "\n",
    "#Why It Is Needed\n",
    "#Gradient descent is used to minimize the loss function and find the best weights for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80410623",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(x_train_scaled.shape[1])\n",
    "b = 0.0\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    w,b = update_weights(x_train_scaled, y_train.values, w, b, lr)\n",
    "\n",
    "#What This Step Does\n",
    "#Trains the logistic regression model using gradient descent.\n",
    "\n",
    "#Why It Is Needed\n",
    "#We need to optimize the weights to minimize the loss and improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57783ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(p, threshold=0.5):\n",
    "    return (p >= threshold).astype(int)\n",
    "\n",
    "#What This Step Does\n",
    "#Converts predicted probabilities into binary class labels based on a threshold.\n",
    "\n",
    "#Why It Is Needed\n",
    "#We need to convert probabilities into class predictions to evaluate accuracy and make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bfcb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = predict_probability(x_test_scaled, w, b)\n",
    "\n",
    "y_pred_05 = predict_label(p_test, threshold=0.5)\n",
    "y_pred_07 = predict_label(p_test, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a30c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (0.5): 0.8604651162790697\n",
      "Accuracy (0.7): 0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (0.5):\", np.mean(y_pred_05 == y_test))\n",
    "print(\"Accuracy (0.7):\", np.mean(y_pred_07 == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c8c58",
   "metadata": {},
   "source": [
    "Logistic regression differs from perceptron because perceptron gives a hard YES/NO decision, while logistic regression outputs a probability representing confidence. The sigmoid function is important because it converts the linear score into a smooth value between 0 and 1, preserving uncertainty near the decision boundary. However, logistic regression still creates a linear decision boundary, so it cannot solve non-linear problems such as XOR. That limitation remains unsolved in this model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
